{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be7fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from itertools import chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bef8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "dtasets= [\"train\", \"dev\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_={'train':{'id':[], 'labels':[], 'sentences':[]}, \n",
    "         'dev':{'id':[], 'labels':[], 'sentences':[]}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325f2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for dta in dtasets:\n",
    "        with open(\"train_dev/en-\"+dta+\".conll\", 'r') as f:\n",
    "            data=f.read()\n",
    "            data=data.split('\\n\\n')\n",
    "        \n",
    "        lines=[]\n",
    "        for lino in range(len(data)):\n",
    "            lino=data[lino].split('\\n')[1:]\n",
    "            lines.append(lino)\n",
    "            \n",
    "        for line in lines:\n",
    "            texts=[]\n",
    "            labels=[]\n",
    "            for index, word in enumerate(line):\n",
    "                if index==0:\n",
    "                    part=word.split()\n",
    "                    data_[dta]['id'].append(part[2])\n",
    "                \n",
    "                else:\n",
    "                    split_line=word.split('_')\n",
    "                    split_line=[x.strip() for x in split_line]\n",
    "                    split_line=list(filter(lambda x:x!=\"\", split_line))\n",
    "                    text, label = split_line\n",
    "                    texts.append(text)\n",
    "                    labels.append(label)\n",
    "            \n",
    "            data_[dta]['labels'].append(labels)\n",
    "            data_[dta]['sentences'].append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a171819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs=data_['train']['labels']\n",
    "sentnc=data_['train']['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b266e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2efbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "model=BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f19495",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=[]\n",
    "\n",
    "for text in dtasets:\n",
    "    for ner_labels in data_[text]['labels']:\n",
    "        for label in ner_labels:\n",
    "            unique_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081f7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=set(unique_labels) #67 labels\n",
    "len(unique_labels)\n",
    "#map each label to its representation and vice versa\n",
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64c92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We only provide a label to the first sub-word of each splitted token. The continuation of the sub-word then will simply have ‘-100’ as a label. All tokens that don’t have word_ids will also be labeled with ‘-100’.\n",
    "#We provide the same label among all of the sub-words that belong to the same token. All tokens that don’t have word_ids will be labeled with ‘-100’\n",
    "import torch\n",
    "\n",
    "\n",
    "def align_label(texts, labels):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=30, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd899aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=[]\n",
    "\n",
    "for i in sentnc:\n",
    "    hello=''\n",
    "    for j in i:\n",
    "        hello+=j\n",
    "        hello+=' '\n",
    "    txt.append(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24024637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, Trainer\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "metric=evaluate.load('seqeval')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels=p\n",
    "    predictions=np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results=metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattenene_results={\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    \n",
    "    #the following code allows us to see enity levelm trics\n",
    "    \n",
    "    for k in results.keys():\n",
    "        if(k not in flattenene_results.keys()):\n",
    "            flattenene_results[k+\"_f1\"]=results[k][\"f1\"]\n",
    "            \n",
    "    return flattenene_results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9ba386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 7.000e+00, 4.500e+01, 2.480e+02, 1.270e+03,\n",
       "        9.830e+02, 1.125e+03, 2.365e+03, 1.230e+03, 1.176e+03, 2.101e+03,\n",
       "        9.960e+02, 1.705e+03, 7.050e+02, 6.000e+02, 9.700e+02, 3.740e+02,\n",
       "        3.080e+02, 3.480e+02, 8.400e+01, 6.000e+01, 4.900e+01, 9.000e+00,\n",
       "        8.000e+00, 7.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([ 0.  ,  1.36,  2.72,  4.08,  5.44,  6.8 ,  8.16,  9.52, 10.88,\n",
       "        12.24, 13.6 , 14.96, 16.32, 17.68, 19.04, 20.4 , 21.76, 23.12,\n",
       "        24.48, 25.84, 27.2 , 28.56, 29.92, 31.28, 32.64, 34.  , 35.36,\n",
       "        36.72, 38.08, 39.44, 40.8 , 42.16, 43.52, 44.88, 46.24, 47.6 ,\n",
       "        48.96, 50.32, 51.68, 53.04, 54.4 , 55.76, 57.12, 58.48, 59.84,\n",
       "        61.2 , 62.56, 63.92, 65.28, 66.64, 68.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgIElEQVR4nO3dbXCU1cGH8f9KkgXSZEuIyWbHAKlNEU2kNmhIagULBjKEjMUpKG0KI6JU3vIAoyAfoJ2WIDMFWqlUKQPyYuM8o1A60EAYMcggL6ZkBKQUh6BQswYxbAKlGxrO84GH2y7hLZCwOdnrN7Mz7H2fLGfPoLnm7N67LmOMEQAAgGXuCPcEAAAAbgYRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKUeGeQFu5cOGCPv/8c8XFxcnlcoV7OgAA4AYYY9TQ0CCfz6c77rj2XkuHjZjPP/9cqamp4Z4GAAC4CcePH9ddd911zTEdNmLi4uIkXVyE+Pj4MM8GAADciPr6eqWmpjq/x6+lw0bMpZeQ4uPjiRgAACxzI28F4Y29AADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwUlS4J4COqdfMjdcdc2z+sNswEwBAR8VODAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAK0WFewLAreo1c+N1xxybP+w2zAQAcDuxEwMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACs1KKIKSkp0YMPPqi4uDglJSXp8ccf1+HDh0PGGGM0d+5c+Xw+denSRQMHDtTBgwdDxgSDQU2ePFmJiYmKjY1VYWGhTpw4ETKmrq5ORUVF8ng88ng8Kioq0unTp2/uWQIAgA6nRRFTUVGhiRMnateuXSovL9d//vMf5eXl6ezZs86YBQsWaOHChVqyZIn27t0rr9erxx57TA0NDc6Y4uJirVu3TqWlpdqxY4fOnDmjgoICNTU1OWNGjx6tqqoqlZWVqaysTFVVVSoqKmqFpwwAADoClzHG3OwPnzx5UklJSaqoqNAjjzwiY4x8Pp+Ki4v14osvSrq465KcnKyXX35Zzz33nAKBgO68806tXr1ao0aNkiR9/vnnSk1N1aZNmzRkyBAdOnRI9957r3bt2qXs7GxJ0q5du5STk6O///3v6t2793XnVl9fL4/Ho0AgoPj4+Jt9irhJt/P7jPjuJADoOFry+/uW3hMTCAQkSQkJCZKk6upq+f1+5eXlOWPcbrcGDBignTt3SpIqKyt1/vz5kDE+n08ZGRnOmA8++EAej8cJGEnq37+/PB6PMwYAAES2m/4Wa2OMpk2bpocfflgZGRmSJL/fL0lKTk4OGZucnKxPP/3UGRMTE6Nu3bo1G3Pp5/1+v5KSkpr9nUlJSc6YywWDQQWDQed+fX39TT4zAABgg5veiZk0aZI++ugj/elPf2p2zuVyhdw3xjQ7drnLx1xp/LUep6SkxHkTsMfjUWpq6o08DQAAYKmbipjJkydrw4YN2rZtm+666y7nuNfrlaRmuyW1tbXO7ozX61VjY6Pq6uquOeaLL75o9veePHmy2S7PJbNmzVIgEHBux48fv5mnBgAALNGiiDHGaNKkSXrnnXf07rvvKi0tLeR8WlqavF6vysvLnWONjY2qqKhQbm6uJCkrK0vR0dEhY2pqanTgwAFnTE5OjgKBgPbs2eOM2b17twKBgDPmcm63W/Hx8SE3AADQcbXoPTETJ07Um2++qT//+c+Ki4tzdlw8Ho+6dOkil8ul4uJizZs3T+np6UpPT9e8efPUtWtXjR492hk7btw4TZ8+Xd27d1dCQoJmzJihzMxMDR48WJLUp08fDR06VOPHj9drr70mSXr22WdVUFBwQ1cmAQCAjq9FEbN06VJJ0sCBA0OOr1ixQmPHjpUkvfDCCzp37pyef/551dXVKTs7W1u2bFFcXJwzftGiRYqKitLIkSN17tw5DRo0SCtXrlSnTp2cMWvXrtWUKVOcq5gKCwu1ZMmSm3mOAACgA7qlz4lpz/icmPDic2IAADfjtn1ODAAAQLgQMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpR4Z4A0F70mrnxumOOzR92G2YCALgR7MQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArtThitm/fruHDh8vn88nlcmn9+vUh58eOHSuXyxVy69+/f8iYYDCoyZMnKzExUbGxsSosLNSJEydCxtTV1amoqEgej0cej0dFRUU6ffp0i58gAADomFocMWfPnlXfvn21ZMmSq44ZOnSoampqnNumTZtCzhcXF2vdunUqLS3Vjh07dObMGRUUFKipqckZM3r0aFVVVamsrExlZWWqqqpSUVFRS6cLAAA6qKiW/kB+fr7y8/OvOcbtdsvr9V7xXCAQ0PLly7V69WoNHjxYkrRmzRqlpqZq69atGjJkiA4dOqSysjLt2rVL2dnZkqRly5YpJydHhw8fVu/evVs6bQAA0MG0yXti3nvvPSUlJek73/mOxo8fr9raWudcZWWlzp8/r7y8POeYz+dTRkaGdu7cKUn64IMP5PF4nICRpP79+8vj8ThjLhcMBlVfXx9yAwAAHVerR0x+fr7Wrl2rd999V7/5zW+0d+9e/fCHP1QwGJQk+f1+xcTEqFu3biE/l5ycLL/f74xJSkpq9thJSUnOmMuVlJQ475/xeDxKTU1t5WcGAADakxa/nHQ9o0aNcv6ckZGhfv36qWfPntq4caNGjBhx1Z8zxsjlcjn3//vPVxvz32bNmqVp06Y59+vr6wkZAAA6sDa/xDolJUU9e/bUkSNHJEler1eNjY2qq6sLGVdbW6vk5GRnzBdffNHssU6ePOmMuZzb7VZ8fHzIDQAAdFxtHjGnTp3S8ePHlZKSIknKyspSdHS0ysvLnTE1NTU6cOCAcnNzJUk5OTkKBALas2ePM2b37t0KBALOGAAAENla/HLSmTNn9Mknnzj3q6urVVVVpYSEBCUkJGju3Ll64oknlJKSomPHjumll15SYmKifvSjH0mSPB6Pxo0bp+nTp6t79+5KSEjQjBkzlJmZ6Vyt1KdPHw0dOlTjx4/Xa6+9Jkl69tlnVVBQwJVJAABA0k1EzIcffqhHH33UuX/pfShjxozR0qVLtX//fq1atUqnT59WSkqKHn30Ub311luKi4tzfmbRokWKiorSyJEjde7cOQ0aNEgrV65Up06dnDFr167VlClTnKuYCgsLr/nZNAAAILK0OGIGDhwoY8xVz2/evPm6j9G5c2e98soreuWVV646JiEhQWvWrGnp9AAAQITgu5MAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFgpKtwTwO3Ta+bG6445Nn/YbZgJAAC3jp0YAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlrk5C2HC1FADgVrATAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKfE4M2rUb+SwZAEBkYicGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJX4nBi0GJ/dAgBoD9iJAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAVmpxxGzfvl3Dhw+Xz+eTy+XS+vXrQ84bYzR37lz5fD516dJFAwcO1MGDB0PGBINBTZ48WYmJiYqNjVVhYaFOnDgRMqaurk5FRUXyeDzyeDwqKirS6dOnW/wEAQBAx9TiiDl79qz69u2rJUuWXPH8ggULtHDhQi1ZskR79+6V1+vVY489poaGBmdMcXGx1q1bp9LSUu3YsUNnzpxRQUGBmpqanDGjR49WVVWVysrKVFZWpqqqKhUVFd3EUwQAAB1RVEt/ID8/X/n5+Vc8Z4zR4sWLNXv2bI0YMUKS9MYbbyg5OVlvvvmmnnvuOQUCAS1fvlyrV6/W4MGDJUlr1qxRamqqtm7dqiFDhujQoUMqKyvTrl27lJ2dLUlatmyZcnJydPjwYfXu3ftmny8AAOggWvU9MdXV1fL7/crLy3OOud1uDRgwQDt37pQkVVZW6vz58yFjfD6fMjIynDEffPCBPB6PEzCS1L9/f3k8HmfM5YLBoOrr60NuAACg42rViPH7/ZKk5OTkkOPJycnOOb/fr5iYGHXr1u2aY5KSkpo9flJSkjPmciUlJc77Zzwej1JTU2/5+QAAgParxS8n3QiXyxVy3xjT7NjlLh9zpfHXepxZs2Zp2rRpzv36+npCBo5eMzeGewoAgFbWqjsxXq9XkprtltTW1jq7M16vV42Njaqrq7vmmC+++KLZ4588ebLZLs8lbrdb8fHxITcAANBxtepOTFpamrxer8rLy/XAAw9IkhobG1VRUaGXX35ZkpSVlaXo6GiVl5dr5MiRkqSamhodOHBACxYskCTl5OQoEAhoz549euihhyRJu3fvViAQUG5ubmtOGZdhxwIAYIsWR8yZM2f0ySefOPerq6tVVVWlhIQE9ejRQ8XFxZo3b57S09OVnp6uefPmqWvXrho9erQkyePxaNy4cZo+fbq6d++uhIQEzZgxQ5mZmc7VSn369NHQoUM1fvx4vfbaa5KkZ599VgUFBVyZBAAAJN1ExHz44Yd69NFHnfuX3ocyZswYrVy5Ui+88ILOnTun559/XnV1dcrOztaWLVsUFxfn/MyiRYsUFRWlkSNH6ty5cxo0aJBWrlypTp06OWPWrl2rKVOmOFcxFRYWXvWzaQDb3MiO17H5w27DTADAXi5jjAn3JNpCfX29PB6PAoEA74/5f7xUdOtaKyyIGAC4spb8/ua7kwAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWiwj0BwCa9Zm687phj84fdhpkAANiJAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgpahwTwDoaHrN3BjuKQBARGAnBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFZq9YiZO3euXC5XyM3r9TrnjTGaO3eufD6funTpooEDB+rgwYMhjxEMBjV58mQlJiYqNjZWhYWFOnHiRGtPFQAAWKxNdmLuu+8+1dTUOLf9+/c75xYsWKCFCxdqyZIl2rt3r7xerx577DE1NDQ4Y4qLi7Vu3TqVlpZqx44dOnPmjAoKCtTU1NQW0wUAABZqky+AjIqKCtl9ucQYo8WLF2v27NkaMWKEJOmNN95QcnKy3nzzTT333HMKBAJavny5Vq9ercGDB0uS1qxZo9TUVG3dulVDhgxpiykDAADLtMlOzJEjR+Tz+ZSWlqYnn3xSR48elSRVV1fL7/crLy/PGet2uzVgwADt3LlTklRZWanz58+HjPH5fMrIyHDGXEkwGFR9fX3IDQAAdFytHjHZ2dlatWqVNm/erGXLlsnv9ys3N1enTp2S3++XJCUnJ4f8THJysnPO7/crJiZG3bp1u+qYKykpKZHH43FuqamprfzMAABAe9LqEZOfn68nnnhCmZmZGjx4sDZu3Cjp4stGl7hcrpCfMcY0O3a5642ZNWuWAoGAczt+/PgtPAsAANDetfkl1rGxscrMzNSRI0ec98lcvqNSW1vr7M54vV41Njaqrq7uqmOuxO12Kz4+PuQGAAA6rjaPmGAwqEOHDiklJUVpaWnyer0qLy93zjc2NqqiokK5ubmSpKysLEVHR4eMqamp0YEDB5wxAAAArX510owZMzR8+HD16NFDtbW1+tWvfqX6+nqNGTNGLpdLxcXFmjdvntLT05Wenq558+apa9euGj16tCTJ4/Fo3Lhxmj59urp3766EhATNmDHDeXkKAABAaoOIOXHihJ566il9+eWXuvPOO9W/f3/t2rVLPXv2lCS98MILOnfunJ5//nnV1dUpOztbW7ZsUVxcnPMYixYtUlRUlEaOHKlz585p0KBBWrlypTp16tTa0wUAAJZyGWNMuCfRFurr6+XxeBQIBHh/zP/rNXNjuKeAFjg2f1i4pwAAt11Lfn/z3UkAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArtfq3WANoHTfyhZ18SSSASMZODAAAsBIRAwAArMTLSUAHx8tSADoqdmIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJW4Ogmw2I1ceQQAHRU7MQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAAr8WF3HQQfegYAiDTsxAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKwUFe4JAAi/XjM3XnfMsfnDbsNMAODGsRMDAACsRMQAAAAr8XISgBvCS04A2ht2YgAAgJXYiQHQatitAXA7ETEWuJFfDAAARBpeTgIAAFZq9xHz6quvKi0tTZ07d1ZWVpbef//9cE8JAAC0A+06Yt566y0VFxdr9uzZ2rdvn37wgx8oPz9fn332WbinBgAAwqxdR8zChQs1btw4PfPMM+rTp48WL16s1NRULV26NNxTAwAAYdZu39jb2NioyspKzZw5M+R4Xl6edu7c2Wx8MBhUMBh07gcCAUlSfX192070FmXM2RzuKQC3VY//+d/b9ncd+MWQ2/Z3AWgdl35vG2OuO7bdRsyXX36ppqYmJScnhxxPTk6W3+9vNr6kpES/+MUvmh1PTU1tszkCaN88i8M9AwA3q6GhQR6P55pj2m3EXOJyuULuG2OaHZOkWbNmadq0ac79Cxcu6KuvvlL37t2vOP5W1NfXKzU1VcePH1d8fHyrPrZNWIeLWIevsRYXsQ4XsQ5fYy0uupF1MMaooaFBPp/vuo/XbiMmMTFRnTp1arbrUltb22x3RpLcbrfcbnfIsW9+85ttOUXFx8dH9D/GS1iHi1iHr7EWF7EOF7EOX2MtLrreOlxvB+aSdvvG3piYGGVlZam8vDzkeHl5uXJzc8M0KwAA0F60250YSZo2bZqKiorUr18/5eTk6PXXX9dnn32mCRMmhHtqAAAgzNp1xIwaNUqnTp3SL3/5S9XU1CgjI0ObNm1Sz549wzovt9utOXPmNHv5KtKwDhexDl9jLS5iHS5iHb7GWlzU2uvgMjdyDRMAAEA7027fEwMAAHAtRAwAALASEQMAAKxExAAAACsRMS306quvKi0tTZ07d1ZWVpbef//9cE+pzW3fvl3Dhw+Xz+eTy+XS+vXrQ84bYzR37lz5fD516dJFAwcO1MGDB8Mz2TZUUlKiBx98UHFxcUpKStLjjz+uw4cPh4yJhLVYunSp7r//fufDqnJycvTXv/7VOR8Ja3AlJSUlcrlcKi4udo5FylrMnTtXLpcr5Ob1ep3zkbIOkvTPf/5TP/3pT9W9e3d17dpV3/3ud1VZWemcj4S16NWrV7N/Dy6XSxMnTpTUymtgcMNKS0tNdHS0WbZsmfn444/N1KlTTWxsrPn000/DPbU2tWnTJjN79mzz9ttvG0lm3bp1Iefnz59v4uLizNtvv232799vRo0aZVJSUkx9fX14JtxGhgwZYlasWGEOHDhgqqqqzLBhw0yPHj3MmTNnnDGRsBYbNmwwGzduNIcPHzaHDx82L730komOjjYHDhwwxkTGGlxuz549plevXub+++83U6dOdY5HylrMmTPH3Hfffaampsa51dbWOucjZR2++uor07NnTzN27Fize/duU11dbbZu3Wo++eQTZ0wkrEVtbW3Iv4Xy8nIjyWzbts0Y07prQMS0wEMPPWQmTJgQcuyee+4xM2fODNOMbr/LI+bChQvG6/Wa+fPnO8f+/e9/G4/HY/7whz+EYYa3T21trZFkKioqjDGRvRbdunUzf/zjHyNyDRoaGkx6eropLy83AwYMcCImktZizpw5pm/fvlc8F0nr8OKLL5qHH374qucjaS3+29SpU83dd99tLly40OprwMtJN6ixsVGVlZXKy8sLOZ6Xl6edO3eGaVbhV11dLb/fH7IubrdbAwYM6PDrEggEJEkJCQmSInMtmpqaVFpaqrNnzyonJyci12DixIkaNmyYBg8eHHI80tbiyJEj8vl8SktL05NPPqmjR49Kiqx12LBhg/r166cf//jHSkpK0gMPPKBly5Y55yNpLS5pbGzUmjVr9PTTT8vlcrX6GhAxN+jLL79UU1NTsy+fTE5ObvYllZHk0nOPtHUxxmjatGl6+OGHlZGRISmy1mL//v36xje+IbfbrQkTJmjdunW69957I2oNJKm0tFR/+9vfVFJS0uxcJK1Fdna2Vq1apc2bN2vZsmXy+/3Kzc3VqVOnImodjh49qqVLlyo9PV2bN2/WhAkTNGXKFK1atUpSZP2buGT9+vU6ffq0xo4dK6n116Bdf+1Ae+RyuULuG2OaHYtEkbYukyZN0kcffaQdO3Y0OxcJa9G7d29VVVXp9OnTevvttzVmzBhVVFQ45yNhDY4fP66pU6dqy5Yt6ty581XHRcJa5OfnO3/OzMxUTk6O7r77br3xxhvq37+/pMhYhwsXLqhfv36aN2+eJOmBBx7QwYMHtXTpUv3sZz9zxkXCWlyyfPly5efny+fzhRxvrTVgJ+YGJSYmqlOnTs1Ksba2tllRRpJLVyBE0rpMnjxZGzZs0LZt23TXXXc5xyNpLWJiYvTtb39b/fr1U0lJifr27avf/va3EbUGlZWVqq2tVVZWlqKiohQVFaWKigr97ne/U1RUlPN8I2EtLhcbG6vMzEwdOXIkov5NpKSk6N577w051qdPH3322WeSIuv/EZL06aefauvWrXrmmWecY629BkTMDYqJiVFWVpbKy8tDjpeXlys3NzdMswq/tLQ0eb3ekHVpbGxURUVFh1sXY4wmTZqkd955R++++67S0tJCzkfSWlzOGKNgMBhRazBo0CDt379fVVVVzq1fv376yU9+oqqqKn3rW9+KmLW4XDAY1KFDh5SSkhJR/ya+//3vN/vYhX/84x/OlxZH0lpI0ooVK5SUlKRhw4Y5x1p9DW75bccR5NIl1suXLzcff/yxKS4uNrGxsebYsWPhnlqbamhoMPv27TP79u0zkszChQvNvn37nEvL58+fbzwej3nnnXfM/v37zVNPPdXhLhk0xpif//znxuPxmPfeey/k8sF//etfzphIWItZs2aZ7du3m+rqavPRRx+Zl156ydxxxx1my5YtxpjIWIOr+e+rk4yJnLWYPn26ee+998zRo0fNrl27TEFBgYmLi3P+3xgp67Bnzx4TFRVlfv3rX5sjR46YtWvXmq5du5o1a9Y4YyJlLZqamkyPHj3Miy++2Oxca64BEdNCv//9703Pnj1NTEyM+d73vudcXtuRbdu2zUhqdhszZowx5uJlg3PmzDFer9e43W7zyCOPmP3794d30m3gSmsgyaxYscIZEwlr8fTTTzv/Ddx5551m0KBBTsAYExlrcDWXR0ykrMWlz/mIjo42Pp/PjBgxwhw8eNA5HynrYIwxf/nLX0xGRoZxu93mnnvuMa+//nrI+UhZi82bNxtJ5vDhw83OteYauIwx5iZ3igAAAMKG98QAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACs9H8tHjLKaMXlJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths=[len(sent) for sent in sentnc]\n",
    "lengths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf7be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "labels1=data_['dev']['labels']\n",
    "sentences2=data_['dev']['sentences']\n",
    "enclose=[]\n",
    "\n",
    "for sentenc in sentences2:\n",
    "    hi=''\n",
    "    for wor in sentenc:\n",
    "        hi+=wor\n",
    "        hi+=' '\n",
    "    enclose.append(hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18fab139",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenizer(txt, padding='max_length', max_length=30, truncation=True)\n",
    "tokens2=tokenizer(enclose, padding='max_length', max_length=30, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc67047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DataSequence(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, tokos, label, sentence_use):  \n",
    "        self.tokens=tokos \n",
    "        self.labels=[align_label(i,j) for i,j in zip(sentence_use, label)]\n",
    "   \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        item ={key: torch.tensor(val[indx]) for key, val in self.tokens.items()}\n",
    "        item['labels']=torch.tensor(self.labels[indx])\n",
    "        return item\n",
    "\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')    \n",
    "train=DataSequence(tokens, lbs, txt)    \n",
    "val=DataSequence(enclose, labels1, enclose)\n",
    "\n",
    "model2=model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7d785f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataSequence at 0x2c053f4f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=dm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9e02809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'O'), ('come', 'O'), ('from', 'O'), ('Kathmandu', 'B-location'), ('valley,', 'I-location'), ('Nepal', 'B-location')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_tokens_with_entities(raw_text: str):\n",
    "    # split the text by spaces only if the space does not occur between square brackets\n",
    "    # we do not want to split \"multi-word\" entity value yet\n",
    "    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n",
    "\n",
    "    # a regex for matching the annotation according to our notation [entity_value](entity_name)\n",
    "    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n",
    "    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n",
    "\n",
    "    tokens_with_entities = []\n",
    "\n",
    "    for raw_token in raw_tokens:\n",
    "        match = entity_value_pattern_compiled.match(raw_token)\n",
    "        if match:\n",
    "            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n",
    "\n",
    "            # we prefix the name of entity differently\n",
    "            # B- indicates beginning of an entity\n",
    "            # I- indicates the token is not a new entity itself but rather a part of existing one\n",
    "            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n",
    "                entity_prefix = \"B\" if i == 0 else \"I\"\n",
    "                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n",
    "                tokens_with_entities.append((raw_entity_token, entity_name))\n",
    "        else:\n",
    "            tokens_with_entities.append((raw_token, \"O\"))\n",
    "\n",
    "    return tokens_with_entities\n",
    "\n",
    "\n",
    "\n",
    "print(get_tokens_with_entities(\"I come from [Kathmandu valley,](location) [Nepal](location)\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64671aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens           :  ('I', 'come', 'from', 'Kathmanduu', 'valley,', 'Nepal')\n",
      "After subword tokenization:  ['[CLS]', 'i', 'come', 'from', 'kathmandu', '##u', 'valley', ',', 'nepal', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# note that I purposefully misspell Kathmandu to Kathamanduu\n",
    "sample_input = \"I come from [Kathmanduu valley,](location) [Nepal](location)\"\n",
    "tokens, entities = list(zip(*get_tokens_with_entities(sample_input)))\n",
    "tokenized_input = tokenizer(tokens, is_split_into_words=True)\n",
    "print(\"Original tokens           : \", tokens)\n",
    "print(\"After subword tokenization: \", tokenizer.convert_ids_to_tokens(tokenized_input['input_ids']))\n",
    "# Original tokens           :  ('I', 'come', 'from', 'Kathmanduu', 'valley,', 'Nepal')\n",
    "# After subword tokenization:  ['[CLS]', 'i', 'come', 'from', 'kathmandu', '##u', 'valley', ',', 'nepal', '[SEP]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8531c2a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NERDataMaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 37\u001b[0m\n\u001b[1;32m      1\u001b[0m raw_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m[40\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m](display_size) [LED](display_type) TV\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSpecifications: [16″](display_size) HD READY [LED](display_type) TV.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mWarranty: [3 Years](warranty) wrranty\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m dm \u001b[38;5;241m=\u001b[39m \u001b[43mNERDataMaker\u001b[49m(raw_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal examples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dm)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(dm[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NERDataMaker' is not defined"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "[40\"](display_size) [LED](display_type) TV\n",
    "Specifications: [16″](display_size) HD READY [LED](display_type) TV.\n",
    "[1 Year](warranty) Warranty\n",
    "Rowa [29\"](display_size) [LED](display_type) TV\n",
    "Highlights:- 48\"Full HD [LED](display_type) TV Triple Protection\n",
    "[80cm](display_size) (32) HD Flat TV K4000 Series 4\n",
    "[32\"](display_size) LED, [2 yrs](warranty) full warranty, All care protection, Integrated Sound Station- Tweeter/20w, Family tv 2.0, Louvre Desing, Mega dynamic contract ratio, Hyper real engine, USB movie\n",
    "CG 32D0003 [LED](display_type) TV\n",
    "Screen Size : [43″](display_size)\n",
    "Resolution : 1920*1080p\n",
    "Response time : [8ms](response_time)\n",
    "USB : Yes (Music+Photo+Movie)\n",
    "Analog AV Out : Yes\n",
    "Power Supply : 110~240V 50-60Hz\n",
    "WEGA [32 Inch](display_size) SMART DLED TV HI Sound Double Glass - (Black)\n",
    "Model: [32\"](display_size) Smart DLED TV HI Sound\n",
    "Hisense HX32N2176 [32\"Inch](display_size) Full HD [Led](display_type) Tv\n",
    "[32 Inch](display_size) [1366x768](display_resolution) pixels HD LED TV\n",
    "[43 inch](display_size) [LED](display_type) TV\n",
    "[2 Years](warranty) Warranty & 1 Year Service Warranty\n",
    "[1920 X 1080](display_resolution) Full HD\n",
    "[Technos](brand) [39 Inch](display_size) Curved Smart [LED](display_type) TV E39DU2000 With Wallmount\n",
    "24″ Led Display Stylish Display Screen resolution : [1280 × 720](display_resolution) (HD Ready) USB : Yes VGS : Yes\n",
    "Technos 24K5 [24 Inch](display_size) LED TV\n",
    "Technos Led Tv [18.5″ Inch](display_size) (1868tw)\n",
    "[18.5 inch](display_size) stylish LED dsiplay [1280 x 720p](display_resolution) HD display 2 acoustic speaker USB and HDMI port Technos brand\n",
    "15.6 ” Led Display Display Screen resolution : 1280 720 (HD Ready) USB : Yes VGS : Yes HDMI : Yes Screen Technology : [led](display_type)\n",
    "Model:CG55D1004U\n",
    "Screen Size: [55\"](display_size)\n",
    "Resolution: [3840x2160p](display_resolution)\n",
    "Power Supply: 100~240 V/AC\n",
    "Sound Output (RMS): 8W + 8W\n",
    "Warranty: [3 Years](warranty) wrranty\n",
    "\"\"\"\n",
    "\n",
    "dm = NERDataMaker(raw_text.split(\"\\n\"))\n",
    "print(f\"total examples = {len(dm)}\")\n",
    "print(dm[0:3])\n",
    "\n",
    "# total examples = 35\n",
    "# [{'id': 0, 'ner_tags': [0], 'tokens': ['']}, {'id': 1, 'ner_tags': [2, 3, 0], 'tokens': ['40\"', 'LED', 'TV']}, {'id': 2, 'ner_tags': [0, 2, 0, 0, 3, 0], 'tokens': ['Specifications:', '16″', 'HD', 'READY', 'LED', 'TV.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68285525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269162f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
